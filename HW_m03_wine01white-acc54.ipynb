{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665327427202,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "8qtNdNTGPSxh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665329164058,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "Z7p71Nq6PxEh"
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/gabenazario/wine-quality-classification-rdm-forest-keras\n",
    "\n",
    "#data = pd.read_csv(\"~/datacsv/Churn_Modelling.csv\")\n",
    "df_red = pd.read_csv(\"~/datacsv/winequality-red.csv\", sep=',')   #red wine UCI dataset\n",
    "df_white = pd.read_csv(\"~/datacsv/winequality-white.csv\", sep=';')   #red wine UCI dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665329166860,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "YNIOl21TP_rE",
    "outputId": "899b2c2a-7235-48a5-e2c1-a9a0d8e2047d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4        5  \n",
       "1         9.8        5  \n",
       "2         9.8        5  \n",
       "3         9.8        6  \n",
       "4         9.4        5  \n",
       "...       ...      ...  \n",
       "1594     10.5        5  \n",
       "1595     11.2        6  \n",
       "1596     11.0        6  \n",
       "1597     10.2        5  \n",
       "1598     11.0        6  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_white"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1599, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_red.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_white.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df_red.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "df_white.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1665329938563,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "Pw242S_QWI1z",
    "outputId": "cc2b0149-6e28-4b95-ff3c-f767a7814d2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_red.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fixed acidity           0\n",
       "volatile acidity        0\n",
       "citric acid             0\n",
       "residual sugar          0\n",
       "chlorides               0\n",
       "free sulfur dioxide     0\n",
       "total sulfur dioxide    0\n",
       "density                 0\n",
       "pH                      0\n",
       "sulphates               0\n",
       "alcohol                 0\n",
       "quality                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_white.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Histogram\n",
    "fig, ax = plt.subplots(1, 2)\n",
    " \n",
    "ax[0].hist(df_red.alcohol, 10, facecolor ='red',alpha = 0.5, label =\"Red wine\")\n",
    " \n",
    "ax[1].hist(df_white.alcohol, 10, facecolor ='white',ec =\"black\", lw = 0.5, alpha = 0.5,label =\"White wine\")\n",
    " \n",
    "fig.subplots_adjust(left = 0, right = 1, bottom = 0,top = 0.5, hspace = 0.05, wspace = 1)\n",
    " \n",
    "ax[0].set_ylim([0, 1000])\n",
    "ax[0].set_xlabel(\"Alcohol in % Vol\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[1].set_ylim([0, 1000])\n",
    "ax[1].set_xlabel(\"Alcohol in % Vol\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    " \n",
    "fig.suptitle(\"Distribution of Alcohol in % Vol\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create Histogram\n",
    "fig, ax = plt.subplots(1, 2)\n",
    " \n",
    "ax[0].hist(df_red.quality, 10, facecolor ='red',alpha = 0.5, label =\"Red wine\")\n",
    " \n",
    "ax[1].hist(df_white.quality, 10, facecolor ='white',ec =\"black\", lw = 0.5, alpha = 0.5,label =\"White wine\")\n",
    " \n",
    "fig.subplots_adjust(left = 0, right = 1, bottom = 0,top = 0.5, hspace = 0.05, wspace = 1)\n",
    " \n",
    "ax[0].set_ylim([0, 1000])\n",
    "ax[0].set_xlabel(\"quality\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[1].set_ylim([0, 1000])\n",
    "ax[1].set_xlabel(\"quality\")\n",
    "ax[1].set_ylabel(\"Frequency\")\n",
    " \n",
    "fig.suptitle(\"Distribution of quality\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665330039050,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "2uniUlaQZnBJ"
   },
   "outputs": [],
   "source": [
    "#data1=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1665330052054,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "rqbEg87HQIf_"
   },
   "outputs": [],
   "source": [
    "x = df_white.iloc[:,0:11].values\n",
    "y = df_white.iloc[:,11].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665330057103,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "FAFOgQSTQUhB",
    "outputId": "afb83821-572b-4e24-808b-35312ee92f37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  3.  ,  0.45,  8.8 ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  3.3 ,  0.49,  9.5 ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  3.26,  0.44, 10.1 ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  2.99,  0.46,  9.4 ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  3.34,  0.38, 12.8 ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  3.26,  0.32, 11.8 ]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665330060482,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "RN7DLB4IQWDc",
    "outputId": "440eaabc-8c05-4db7-9e6a-c9d0b751d8a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 6, 6, ..., 6, 7, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "UEENwze_UTyC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 6, 7, 4, 8, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_red.quality.unique()    #3,4,5,6,7,8.  - so there are 6 quality levels/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 5, 7, 8, 4, 3, 9])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_white.quality.unique()   # 3,4,5,6,7,8,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4898, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665330065074,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "TVNxfzm5QW8f"
   },
   "outputs": [],
   "source": [
    "# splitting the training & test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3918, 11), (980, 11), (3918,), (980,))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape ,x_test.shape, y_train.shape ,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1665330068344,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "r0LO-ofKUhSB"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mc=MinMaxScaler()\n",
    "x_train1 = mc.fit_transform( x_train)\n",
    "X_test1 = mc.fit_transform( x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1665329231326,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "qCrZ1bbYRHjL"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Activation\n",
    "\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665330071253,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "YzDCMeK3Rt6G"
   },
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model=Sequential()\n",
    "\n",
    "# Build input layer & Hidden layer\n",
    "model.add(Dense(units=88, activation='relu', input_dim=11))\n",
    "model.add(Dropout(rate=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1665330074215,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "f7YZxhXsSI-F"
   },
   "outputs": [],
   "source": [
    "# Building second layer\n",
    "model.add(Dense(units=44,activation ='relu'))\n",
    "model.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 3rd layer\n",
    "model.add(Dense(units=22,activation ='relu'))\n",
    "model.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building 4th layer\n",
    "model.add(Dense(units=11,activation ='relu'))\n",
    "model.add(Dropout(rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "executionInfo": {
     "elapsed": 409,
     "status": "ok",
     "timestamp": 1665330076767,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "fWbqbVchShPq"
   },
   "outputs": [],
   "source": [
    "#Adding outer layer\n",
    "#model.add(Dense(units = 1, activation='sigmoid'))\n",
    "model.add(Dense(units = 1, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1665330079698,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "aFJmCSsdTAqM"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mae')   #Test accuracy: 0.590625  epochs=300\n",
    "#model.compile(loss='mae', optimizer = 'adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5569,
     "status": "ok",
     "timestamp": 1665330085260,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "deIBbz04T3f2",
    "outputId": "98823d0e-8c13-40ec-9b4a-917724012d48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "98/98 [==============================] - 1s 2ms/step - loss: 2.5236 - val_loss: 1.5295\n",
      "Epoch 2/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.8801 - val_loss: 1.2390\n",
      "Epoch 3/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.6048 - val_loss: 1.3065\n",
      "Epoch 4/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.4143 - val_loss: 1.0259\n",
      "Epoch 5/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.3481 - val_loss: 1.0247\n",
      "Epoch 6/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.3022 - val_loss: 0.8518\n",
      "Epoch 7/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.2593 - val_loss: 1.1949\n",
      "Epoch 8/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.2087 - val_loss: 1.3133\n",
      "Epoch 9/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.2147 - val_loss: 1.0637\n",
      "Epoch 10/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.2068 - val_loss: 0.7703\n",
      "Epoch 11/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.1607 - val_loss: 1.0244\n",
      "Epoch 12/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.1264 - val_loss: 0.8872\n",
      "Epoch 13/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0861 - val_loss: 1.2248\n",
      "Epoch 14/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0675 - val_loss: 1.1795\n",
      "Epoch 15/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0700 - val_loss: 1.3441\n",
      "Epoch 16/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0409 - val_loss: 0.9426\n",
      "Epoch 17/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0250 - val_loss: 1.5344\n",
      "Epoch 18/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0097 - val_loss: 1.1512\n",
      "Epoch 19/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0087 - val_loss: 1.1549\n",
      "Epoch 20/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 1.0037 - val_loss: 1.1463\n",
      "Epoch 21/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9670 - val_loss: 1.1895\n",
      "Epoch 22/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9853 - val_loss: 1.2893\n",
      "Epoch 23/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9839 - val_loss: 1.0098\n",
      "Epoch 24/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9394 - val_loss: 0.9082\n",
      "Epoch 25/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9463 - val_loss: 0.9269\n",
      "Epoch 26/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9253 - val_loss: 0.9292\n",
      "Epoch 27/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8982 - val_loss: 1.0678\n",
      "Epoch 28/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9109 - val_loss: 1.0718\n",
      "Epoch 29/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.9085 - val_loss: 1.0136\n",
      "Epoch 30/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8930 - val_loss: 1.1940\n",
      "Epoch 31/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8937 - val_loss: 1.0687\n",
      "Epoch 32/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8673 - val_loss: 1.0771\n",
      "Epoch 33/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8827 - val_loss: 0.9980\n",
      "Epoch 34/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8640 - val_loss: 1.0099\n",
      "Epoch 35/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8582 - val_loss: 0.8671\n",
      "Epoch 36/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8712 - val_loss: 1.1785\n",
      "Epoch 37/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8791 - val_loss: 1.1754\n",
      "Epoch 38/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8378 - val_loss: 1.0164\n",
      "Epoch 39/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8234 - val_loss: 1.0249\n",
      "Epoch 40/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8303 - val_loss: 0.8145\n",
      "Epoch 41/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8227 - val_loss: 1.0092\n",
      "Epoch 42/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8442 - val_loss: 1.0295\n",
      "Epoch 43/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8382 - val_loss: 1.0328\n",
      "Epoch 44/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8363 - val_loss: 0.7512\n",
      "Epoch 45/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8129 - val_loss: 0.9074\n",
      "Epoch 46/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8114 - val_loss: 1.0287\n",
      "Epoch 47/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8201 - val_loss: 1.0741\n",
      "Epoch 48/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8182 - val_loss: 0.8580\n",
      "Epoch 49/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7861 - val_loss: 0.8875\n",
      "Epoch 50/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7822 - val_loss: 0.8659\n",
      "Epoch 51/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.8141 - val_loss: 0.7596\n",
      "Epoch 52/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7902 - val_loss: 0.7802\n",
      "Epoch 53/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7757 - val_loss: 0.7670\n",
      "Epoch 54/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7804 - val_loss: 0.8360\n",
      "Epoch 55/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7861 - val_loss: 0.9347\n",
      "Epoch 56/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7686 - val_loss: 0.8604\n",
      "Epoch 57/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7531 - val_loss: 0.8409\n",
      "Epoch 58/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7587 - val_loss: 0.7681\n",
      "Epoch 59/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7633 - val_loss: 0.8154\n",
      "Epoch 60/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7606 - val_loss: 0.8081\n",
      "Epoch 61/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7610 - val_loss: 0.8437\n",
      "Epoch 62/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7297 - val_loss: 0.7786\n",
      "Epoch 63/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7381 - val_loss: 0.8466\n",
      "Epoch 64/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7491 - val_loss: 0.8178\n",
      "Epoch 65/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7376 - val_loss: 0.8203\n",
      "Epoch 66/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7388 - val_loss: 0.7588\n",
      "Epoch 67/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7245 - val_loss: 0.7299\n",
      "Epoch 68/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7301 - val_loss: 0.8094\n",
      "Epoch 69/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7385 - val_loss: 0.7342\n",
      "Epoch 70/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7284 - val_loss: 0.7269\n",
      "Epoch 71/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7238 - val_loss: 0.6819\n",
      "Epoch 72/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7088 - val_loss: 0.7277\n",
      "Epoch 73/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7302 - val_loss: 0.7725\n",
      "Epoch 74/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7091 - val_loss: 0.7382\n",
      "Epoch 75/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7048 - val_loss: 0.7534\n",
      "Epoch 76/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7050 - val_loss: 0.8047\n",
      "Epoch 77/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7154 - val_loss: 0.7297\n",
      "Epoch 78/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7094 - val_loss: 0.7461\n",
      "Epoch 79/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7078 - val_loss: 0.6816\n",
      "Epoch 80/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6932 - val_loss: 0.7276\n",
      "Epoch 81/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6893 - val_loss: 0.6832\n",
      "Epoch 82/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.7030 - val_loss: 0.6652\n",
      "Epoch 83/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6963 - val_loss: 0.7377\n",
      "Epoch 84/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6984 - val_loss: 0.7296\n",
      "Epoch 85/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6779 - val_loss: 0.6668\n",
      "Epoch 86/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6903 - val_loss: 0.6903\n",
      "Epoch 87/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6851 - val_loss: 0.6939\n",
      "Epoch 88/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6761 - val_loss: 0.7086\n",
      "Epoch 89/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6851 - val_loss: 0.6592\n",
      "Epoch 90/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6949 - val_loss: 0.6994\n",
      "Epoch 91/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6781 - val_loss: 0.7381\n",
      "Epoch 92/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6705 - val_loss: 0.7480\n",
      "Epoch 93/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6806 - val_loss: 0.6135\n",
      "Epoch 94/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6760 - val_loss: 0.6639\n",
      "Epoch 95/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6734 - val_loss: 0.6775\n",
      "Epoch 96/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6825 - val_loss: 0.6658\n",
      "Epoch 97/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6603 - val_loss: 0.6634\n",
      "Epoch 98/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6481 - val_loss: 0.6629\n",
      "Epoch 99/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6559 - val_loss: 0.6611\n",
      "Epoch 100/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6632 - val_loss: 0.6318\n",
      "Epoch 101/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6580 - val_loss: 0.6707\n",
      "Epoch 102/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6438 - val_loss: 0.7513\n",
      "Epoch 103/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6665 - val_loss: 0.6657\n",
      "Epoch 104/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6522 - val_loss: 0.6341\n",
      "Epoch 105/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6499 - val_loss: 0.7003\n",
      "Epoch 106/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6537 - val_loss: 0.6553\n",
      "Epoch 107/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6562 - val_loss: 0.6940\n",
      "Epoch 108/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6492 - val_loss: 0.6702\n",
      "Epoch 109/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6576 - val_loss: 0.6883\n",
      "Epoch 110/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6476 - val_loss: 0.6454\n",
      "Epoch 111/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6411 - val_loss: 0.6422\n",
      "Epoch 112/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6429 - val_loss: 0.6734\n",
      "Epoch 113/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6529 - val_loss: 0.6649\n",
      "Epoch 114/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6458 - val_loss: 0.6228\n",
      "Epoch 115/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6518 - val_loss: 0.6224\n",
      "Epoch 116/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6272 - val_loss: 0.6405\n",
      "Epoch 117/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6418 - val_loss: 0.6845\n",
      "Epoch 118/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6366 - val_loss: 0.6526\n",
      "Epoch 119/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6411 - val_loss: 0.6443\n",
      "Epoch 120/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6465 - val_loss: 0.6281\n",
      "Epoch 121/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6371 - val_loss: 0.6468\n",
      "Epoch 122/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6318 - val_loss: 0.6068\n",
      "Epoch 123/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6439 - val_loss: 0.6309\n",
      "Epoch 124/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6321 - val_loss: 0.6228\n",
      "Epoch 125/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6190 - val_loss: 0.6215\n",
      "Epoch 126/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6209 - val_loss: 0.6516\n",
      "Epoch 127/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6242 - val_loss: 0.6234\n",
      "Epoch 128/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.6290\n",
      "Epoch 129/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6261 - val_loss: 0.6348\n",
      "Epoch 130/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6259 - val_loss: 0.6540\n",
      "Epoch 131/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6241 - val_loss: 0.6252\n",
      "Epoch 132/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6224 - val_loss: 0.6648\n",
      "Epoch 133/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6195 - val_loss: 0.6142\n",
      "Epoch 134/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6235 - val_loss: 0.6677\n",
      "Epoch 135/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6187 - val_loss: 0.6884\n",
      "Epoch 136/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6319 - val_loss: 0.6384\n",
      "Epoch 137/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6195 - val_loss: 0.6048\n",
      "Epoch 138/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6153 - val_loss: 0.6335\n",
      "Epoch 139/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6184 - val_loss: 0.6022\n",
      "Epoch 140/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6086 - val_loss: 0.6112\n",
      "Epoch 141/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6195 - val_loss: 0.6112\n",
      "Epoch 142/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6098 - val_loss: 0.6244\n",
      "Epoch 143/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6140 - val_loss: 0.6257\n",
      "Epoch 144/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6182 - val_loss: 0.6588\n",
      "Epoch 145/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6152 - val_loss: 0.6126\n",
      "Epoch 146/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6130 - val_loss: 0.6022\n",
      "Epoch 147/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6121 - val_loss: 0.6247\n",
      "Epoch 148/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6114 - val_loss: 0.6603\n",
      "Epoch 149/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6064 - val_loss: 0.6122\n",
      "Epoch 150/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6088 - val_loss: 0.6490\n",
      "Epoch 151/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6095 - val_loss: 0.6249\n",
      "Epoch 152/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6306\n",
      "Epoch 153/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6106 - val_loss: 0.6182\n",
      "Epoch 154/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6008 - val_loss: 0.6095\n",
      "Epoch 155/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6030 - val_loss: 0.6146\n",
      "Epoch 156/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6051 - val_loss: 0.6194\n",
      "Epoch 157/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6068 - val_loss: 0.6103\n",
      "Epoch 158/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6041 - val_loss: 0.6164\n",
      "Epoch 159/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6059 - val_loss: 0.6299\n",
      "Epoch 160/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6231\n",
      "Epoch 161/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6054 - val_loss: 0.6198\n",
      "Epoch 162/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6607\n",
      "Epoch 163/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6008 - val_loss: 0.6054\n",
      "Epoch 164/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5999 - val_loss: 0.6357\n",
      "Epoch 165/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6037 - val_loss: 0.6165\n",
      "Epoch 166/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6012 - val_loss: 0.6004\n",
      "Epoch 167/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5967 - val_loss: 0.6177\n",
      "Epoch 168/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5985 - val_loss: 0.6325\n",
      "Epoch 169/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6011 - val_loss: 0.6136\n",
      "Epoch 170/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5952 - val_loss: 0.6190\n",
      "Epoch 171/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5945 - val_loss: 0.5984\n",
      "Epoch 172/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.6092\n",
      "Epoch 173/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5957 - val_loss: 0.5898\n",
      "Epoch 174/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5982 - val_loss: 0.6131\n",
      "Epoch 175/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5836 - val_loss: 0.6034\n",
      "Epoch 176/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5993 - val_loss: 0.6099\n",
      "Epoch 177/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6232\n",
      "Epoch 178/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5966 - val_loss: 0.6031\n",
      "Epoch 179/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6030 - val_loss: 0.5931\n",
      "Epoch 180/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5915 - val_loss: 0.5910\n",
      "Epoch 181/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5819 - val_loss: 0.6326\n",
      "Epoch 182/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5941 - val_loss: 0.5870\n",
      "Epoch 183/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5934 - val_loss: 0.6422\n",
      "Epoch 184/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5878 - val_loss: 0.6110\n",
      "Epoch 185/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5916 - val_loss: 0.6227\n",
      "Epoch 186/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 0.6639\n",
      "Epoch 187/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5979 - val_loss: 0.6048\n",
      "Epoch 188/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5860 - val_loss: 0.5828\n",
      "Epoch 189/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5835 - val_loss: 0.5841\n",
      "Epoch 190/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5843 - val_loss: 0.6027\n",
      "Epoch 191/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5855 - val_loss: 0.6115\n",
      "Epoch 192/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5928 - val_loss: 0.6181\n",
      "Epoch 193/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5867 - val_loss: 0.6349\n",
      "Epoch 194/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 0.5788\n",
      "Epoch 195/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5838 - val_loss: 0.5758\n",
      "Epoch 196/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5812 - val_loss: 0.5895\n",
      "Epoch 197/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5829 - val_loss: 0.5879\n",
      "Epoch 198/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 0.5776\n",
      "Epoch 199/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5835 - val_loss: 0.6097\n",
      "Epoch 200/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5896 - val_loss: 0.5998\n",
      "Epoch 201/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5843 - val_loss: 0.5989\n",
      "Epoch 202/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5841 - val_loss: 0.6055\n",
      "Epoch 203/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5787 - val_loss: 0.5764\n",
      "Epoch 204/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5839 - val_loss: 0.6380\n",
      "Epoch 205/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5795 - val_loss: 0.6178\n",
      "Epoch 206/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5805 - val_loss: 0.6165\n",
      "Epoch 207/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5862 - val_loss: 0.5937\n",
      "Epoch 208/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5820 - val_loss: 0.6219\n",
      "Epoch 209/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5882 - val_loss: 0.6030\n",
      "Epoch 210/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5806 - val_loss: 0.5889\n",
      "Epoch 211/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5831 - val_loss: 0.5726\n",
      "Epoch 212/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5858 - val_loss: 0.5939\n",
      "Epoch 213/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5747 - val_loss: 0.5933\n",
      "Epoch 214/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5819 - val_loss: 0.6004\n",
      "Epoch 215/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5797 - val_loss: 0.6049\n",
      "Epoch 216/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5764 - val_loss: 0.5885\n",
      "Epoch 217/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.6088\n",
      "Epoch 218/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.5983\n",
      "Epoch 219/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5811 - val_loss: 0.6191\n",
      "Epoch 220/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5868 - val_loss: 0.6403\n",
      "Epoch 221/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5870 - val_loss: 0.6053\n",
      "Epoch 222/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5785 - val_loss: 0.5938\n",
      "Epoch 223/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5743 - val_loss: 0.5812\n",
      "Epoch 224/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5963 - val_loss: 0.5989\n",
      "Epoch 225/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5792 - val_loss: 0.5847\n",
      "Epoch 226/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5766 - val_loss: 0.6166\n",
      "Epoch 227/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5763 - val_loss: 0.5900\n",
      "Epoch 228/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.5999\n",
      "Epoch 229/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5756 - val_loss: 0.5864\n",
      "Epoch 230/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5869 - val_loss: 0.6086\n",
      "Epoch 231/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.6037\n",
      "Epoch 232/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5878 - val_loss: 0.5842\n",
      "Epoch 233/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5790 - val_loss: 0.5784\n",
      "Epoch 234/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5880 - val_loss: 0.6265\n",
      "Epoch 235/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5832 - val_loss: 0.6327\n",
      "Epoch 236/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5695 - val_loss: 0.6082\n",
      "Epoch 237/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5729 - val_loss: 0.6004\n",
      "Epoch 238/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5805 - val_loss: 0.6225\n",
      "Epoch 239/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5842 - val_loss: 0.6190\n",
      "Epoch 240/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5770 - val_loss: 0.6284\n",
      "Epoch 241/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5733 - val_loss: 0.5987\n",
      "Epoch 242/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5751\n",
      "Epoch 243/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5822 - val_loss: 0.6094\n",
      "Epoch 244/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5796 - val_loss: 0.5865\n",
      "Epoch 245/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5743 - val_loss: 0.5804\n",
      "Epoch 246/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5812 - val_loss: 0.5939\n",
      "Epoch 247/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5865 - val_loss: 0.5903\n",
      "Epoch 248/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5762 - val_loss: 0.5879\n",
      "Epoch 249/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5738 - val_loss: 0.5999\n",
      "Epoch 250/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5718 - val_loss: 0.5945\n",
      "Epoch 251/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5801 - val_loss: 0.6269\n",
      "Epoch 252/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5809 - val_loss: 0.5928\n",
      "Epoch 253/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5784 - val_loss: 0.5827\n",
      "Epoch 254/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5713 - val_loss: 0.6010\n",
      "Epoch 255/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5686 - val_loss: 0.5820\n",
      "Epoch 256/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5704 - val_loss: 0.6275\n",
      "Epoch 257/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5676 - val_loss: 0.6205\n",
      "Epoch 258/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5737 - val_loss: 0.5772\n",
      "Epoch 259/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5650 - val_loss: 0.5680\n",
      "Epoch 260/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5667 - val_loss: 0.6177\n",
      "Epoch 261/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5744 - val_loss: 0.5956\n",
      "Epoch 262/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5818 - val_loss: 0.5793\n",
      "Epoch 263/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5765 - val_loss: 0.5940\n",
      "Epoch 264/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5844 - val_loss: 0.5943\n",
      "Epoch 265/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.6229\n",
      "Epoch 266/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5724 - val_loss: 0.6212\n",
      "Epoch 267/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5758 - val_loss: 0.5816\n",
      "Epoch 268/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.5754\n",
      "Epoch 269/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5666 - val_loss: 0.5620\n",
      "Epoch 270/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5849 - val_loss: 0.6246\n",
      "Epoch 271/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5877 - val_loss: 0.5948\n",
      "Epoch 272/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5826 - val_loss: 0.5727\n",
      "Epoch 273/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5893 - val_loss: 0.6040\n",
      "Epoch 274/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5710 - val_loss: 0.5846\n",
      "Epoch 275/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 0.5955\n",
      "Epoch 276/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5707 - val_loss: 0.5908\n",
      "Epoch 277/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5778 - val_loss: 0.6014\n",
      "Epoch 278/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5786 - val_loss: 0.5954\n",
      "Epoch 279/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5832 - val_loss: 0.5739\n",
      "Epoch 280/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5829 - val_loss: 0.6069\n",
      "Epoch 281/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5745 - val_loss: 0.6308\n",
      "Epoch 282/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5807 - val_loss: 0.5732\n",
      "Epoch 283/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5761 - val_loss: 0.5772\n",
      "Epoch 284/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5602 - val_loss: 0.5763\n",
      "Epoch 285/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5670 - val_loss: 0.5610\n",
      "Epoch 286/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5889 - val_loss: 0.5872\n",
      "Epoch 287/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5673 - val_loss: 0.5736\n",
      "Epoch 288/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5708 - val_loss: 0.6767\n",
      "Epoch 289/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5765 - val_loss: 0.5876\n",
      "Epoch 290/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5741 - val_loss: 0.5718\n",
      "Epoch 291/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5819 - val_loss: 0.6073\n",
      "Epoch 292/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5811 - val_loss: 0.5921\n",
      "Epoch 293/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5661 - val_loss: 0.5698\n",
      "Epoch 294/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5692 - val_loss: 0.5713\n",
      "Epoch 295/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5674 - val_loss: 0.5908\n",
      "Epoch 296/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5608 - val_loss: 0.5682\n",
      "Epoch 297/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5721 - val_loss: 0.6203\n",
      "Epoch 298/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5732 - val_loss: 0.5829\n",
      "Epoch 299/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5675 - val_loss: 0.5909\n",
      "Epoch 300/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5763 - val_loss: 0.5717\n",
      "Epoch 301/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5703 - val_loss: 0.5881\n",
      "Epoch 302/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5682 - val_loss: 0.5853\n",
      "Epoch 303/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5655 - val_loss: 0.5777\n",
      "Epoch 304/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5702 - val_loss: 0.6346\n",
      "Epoch 305/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5802 - val_loss: 0.6151\n",
      "Epoch 306/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5598 - val_loss: 0.5804\n",
      "Epoch 307/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5671 - val_loss: 0.5765\n",
      "Epoch 308/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5628 - val_loss: 0.5725\n",
      "Epoch 309/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5748 - val_loss: 0.6073\n",
      "Epoch 310/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5719 - val_loss: 0.5785\n",
      "Epoch 311/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5771 - val_loss: 0.6017\n",
      "Epoch 312/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5939 - val_loss: 0.6004\n",
      "Epoch 313/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5759 - val_loss: 0.5675\n",
      "Epoch 314/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5623 - val_loss: 0.5744\n",
      "Epoch 315/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5690 - val_loss: 0.5795\n",
      "Epoch 316/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5796 - val_loss: 0.6569\n",
      "Epoch 317/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.5904\n",
      "Epoch 318/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5692 - val_loss: 0.6134\n",
      "Epoch 319/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5732 - val_loss: 0.5901\n",
      "Epoch 320/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5724 - val_loss: 0.5791\n",
      "Epoch 321/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5594 - val_loss: 0.6395\n",
      "Epoch 322/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5743 - val_loss: 0.5767\n",
      "Epoch 323/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5688 - val_loss: 0.5713\n",
      "Epoch 324/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5611 - val_loss: 0.6249\n",
      "Epoch 325/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5840 - val_loss: 0.5983\n",
      "Epoch 326/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5619 - val_loss: 0.5754\n",
      "Epoch 327/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5743 - val_loss: 0.5681\n",
      "Epoch 328/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5764 - val_loss: 0.5894\n",
      "Epoch 329/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5825\n",
      "Epoch 330/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5646 - val_loss: 0.5801\n",
      "Epoch 331/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5719 - val_loss: 0.5831\n",
      "Epoch 332/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5815 - val_loss: 0.5758\n",
      "Epoch 333/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5582 - val_loss: 0.5651\n",
      "Epoch 334/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5564 - val_loss: 0.5626\n",
      "Epoch 335/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5668 - val_loss: 0.5713\n",
      "Epoch 336/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5661 - val_loss: 0.5913\n",
      "Epoch 337/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5500 - val_loss: 0.5685\n",
      "Epoch 338/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.5768\n",
      "Epoch 339/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5742 - val_loss: 0.5791\n",
      "Epoch 340/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5739 - val_loss: 0.5705\n",
      "Epoch 341/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5669 - val_loss: 0.5763\n",
      "Epoch 342/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5697 - val_loss: 0.5702\n",
      "Epoch 343/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5879 - val_loss: 0.5886\n",
      "Epoch 344/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.5681\n",
      "Epoch 345/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5668\n",
      "Epoch 346/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5757 - val_loss: 0.5671\n",
      "Epoch 347/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5729 - val_loss: 0.5905\n",
      "Epoch 348/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5865 - val_loss: 0.6039\n",
      "Epoch 349/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5920 - val_loss: 0.5677\n",
      "Epoch 350/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5663 - val_loss: 0.5774\n",
      "Epoch 351/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5715 - val_loss: 0.5939\n",
      "Epoch 352/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5781 - val_loss: 0.5790\n",
      "Epoch 353/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5727 - val_loss: 0.6031\n",
      "Epoch 354/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5648 - val_loss: 0.5643\n",
      "Epoch 355/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5588 - val_loss: 0.5662\n",
      "Epoch 356/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5576 - val_loss: 0.5882\n",
      "Epoch 357/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5629 - val_loss: 0.5625\n",
      "Epoch 358/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5640 - val_loss: 0.5894\n",
      "Epoch 359/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5663 - val_loss: 0.5866\n",
      "Epoch 360/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5702 - val_loss: 0.5923\n",
      "Epoch 361/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5772 - val_loss: 0.5800\n",
      "Epoch 362/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5710 - val_loss: 0.5813\n",
      "Epoch 363/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 0.5939\n",
      "Epoch 364/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5731 - val_loss: 0.5837\n",
      "Epoch 365/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5856 - val_loss: 0.6020\n",
      "Epoch 366/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5751 - val_loss: 0.6401\n",
      "Epoch 367/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5884 - val_loss: 0.5975\n",
      "Epoch 368/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5731 - val_loss: 0.6305\n",
      "Epoch 369/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5750 - val_loss: 0.5624\n",
      "Epoch 370/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5743 - val_loss: 0.5594\n",
      "Epoch 371/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5595 - val_loss: 0.5691\n",
      "Epoch 372/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5603 - val_loss: 0.5576\n",
      "Epoch 373/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5643 - val_loss: 0.5696\n",
      "Epoch 374/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5845 - val_loss: 0.6228\n",
      "Epoch 375/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5916 - val_loss: 0.5800\n",
      "Epoch 376/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5928 - val_loss: 0.6084\n",
      "Epoch 377/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5866 - val_loss: 0.5792\n",
      "Epoch 378/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5793 - val_loss: 0.5691\n",
      "Epoch 379/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.6318\n",
      "Epoch 380/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5785 - val_loss: 0.6035\n",
      "Epoch 381/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5887 - val_loss: 0.5733\n",
      "Epoch 382/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5705 - val_loss: 0.5725\n",
      "Epoch 383/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5644 - val_loss: 0.5719\n",
      "Epoch 384/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5594 - val_loss: 0.5685\n",
      "Epoch 385/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5745 - val_loss: 0.5860\n",
      "Epoch 386/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5736 - val_loss: 0.5635\n",
      "Epoch 387/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5660 - val_loss: 0.5827\n",
      "Epoch 388/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5730 - val_loss: 0.5814\n",
      "Epoch 389/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5799 - val_loss: 0.6215\n",
      "Epoch 390/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5703 - val_loss: 0.6715\n",
      "Epoch 391/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5817 - val_loss: 0.5588\n",
      "Epoch 392/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5710 - val_loss: 0.5849\n",
      "Epoch 393/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5874 - val_loss: 0.5829\n",
      "Epoch 394/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5774 - val_loss: 0.6635\n",
      "Epoch 395/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5984 - val_loss: 0.5686\n",
      "Epoch 396/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5943 - val_loss: 0.5984\n",
      "Epoch 397/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5766 - val_loss: 0.5609\n",
      "Epoch 398/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5705 - val_loss: 0.6666\n",
      "Epoch 399/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5746 - val_loss: 0.5893\n",
      "Epoch 400/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5744 - val_loss: 0.5780\n",
      "Epoch 401/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5850 - val_loss: 0.5749\n",
      "Epoch 402/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.5689\n",
      "Epoch 403/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5559 - val_loss: 0.6353\n",
      "Epoch 404/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5653 - val_loss: 0.6091\n",
      "Epoch 405/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5774 - val_loss: 0.5829\n",
      "Epoch 406/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5691 - val_loss: 0.6248\n",
      "Epoch 407/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5786 - val_loss: 0.5857\n",
      "Epoch 408/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5751 - val_loss: 0.5807\n",
      "Epoch 409/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5686 - val_loss: 0.5920\n",
      "Epoch 410/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5708 - val_loss: 0.5639\n",
      "Epoch 411/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5960 - val_loss: 0.5893\n",
      "Epoch 412/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5881 - val_loss: 0.5641\n",
      "Epoch 413/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5677 - val_loss: 0.5813\n",
      "Epoch 414/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5877 - val_loss: 0.5926\n",
      "Epoch 415/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5642 - val_loss: 0.5794\n",
      "Epoch 416/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5789 - val_loss: 0.6210\n",
      "Epoch 417/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.5592\n",
      "Epoch 418/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6027 - val_loss: 0.5876\n",
      "Epoch 419/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5873 - val_loss: 0.6072\n",
      "Epoch 420/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5833 - val_loss: 0.5900\n",
      "Epoch 421/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5899 - val_loss: 0.5781\n",
      "Epoch 422/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5904 - val_loss: 0.5896\n",
      "Epoch 423/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5856 - val_loss: 0.5737\n",
      "Epoch 424/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5847 - val_loss: 0.5968\n",
      "Epoch 425/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5794 - val_loss: 0.5836\n",
      "Epoch 426/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5847 - val_loss: 0.5919\n",
      "Epoch 427/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5722 - val_loss: 0.5835\n",
      "Epoch 428/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5690 - val_loss: 0.6309\n",
      "Epoch 429/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5843 - val_loss: 0.5789\n",
      "Epoch 430/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.5860\n",
      "Epoch 431/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5683 - val_loss: 0.5827\n",
      "Epoch 432/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5555 - val_loss: 0.5827\n",
      "Epoch 433/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5753 - val_loss: 0.5922\n",
      "Epoch 434/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5597\n",
      "Epoch 435/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5582 - val_loss: 0.5813\n",
      "Epoch 436/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5842 - val_loss: 0.5958\n",
      "Epoch 437/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5835 - val_loss: 0.5724\n",
      "Epoch 438/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.5973\n",
      "Epoch 439/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5892 - val_loss: 0.5793\n",
      "Epoch 440/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5734 - val_loss: 0.5803\n",
      "Epoch 441/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5736 - val_loss: 0.6381\n",
      "Epoch 442/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 0.5978\n",
      "Epoch 443/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6024 - val_loss: 0.5728\n",
      "Epoch 444/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5815 - val_loss: 0.6337\n",
      "Epoch 445/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5864 - val_loss: 0.5854\n",
      "Epoch 446/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5880 - val_loss: 0.5994\n",
      "Epoch 447/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5809 - val_loss: 0.6338\n",
      "Epoch 448/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5919 - val_loss: 0.5669\n",
      "Epoch 449/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5686 - val_loss: 0.5758\n",
      "Epoch 450/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5822 - val_loss: 0.6810\n",
      "Epoch 451/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5938 - val_loss: 0.5695\n",
      "Epoch 452/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5718 - val_loss: 0.5757\n",
      "Epoch 453/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5847 - val_loss: 0.5794\n",
      "Epoch 454/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.6514\n",
      "Epoch 455/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5711 - val_loss: 0.5699\n",
      "Epoch 456/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5847 - val_loss: 0.5774\n",
      "Epoch 457/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5665 - val_loss: 0.5545\n",
      "Epoch 458/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5612 - val_loss: 0.5906\n",
      "Epoch 459/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5926 - val_loss: 0.5911\n",
      "Epoch 460/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5655 - val_loss: 0.5961\n",
      "Epoch 461/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5738 - val_loss: 0.5829\n",
      "Epoch 462/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.6124\n",
      "Epoch 463/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5955 - val_loss: 0.6076\n",
      "Epoch 464/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5755 - val_loss: 0.5738\n",
      "Epoch 465/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5811 - val_loss: 0.5620\n",
      "Epoch 466/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5713 - val_loss: 0.5548\n",
      "Epoch 467/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5643 - val_loss: 0.5623\n",
      "Epoch 468/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5750 - val_loss: 0.5747\n",
      "Epoch 469/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5744 - val_loss: 0.5819\n",
      "Epoch 470/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5827 - val_loss: 0.5787\n",
      "Epoch 471/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5799 - val_loss: 0.5872\n",
      "Epoch 472/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5880 - val_loss: 0.5896\n",
      "Epoch 473/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5686 - val_loss: 0.5950\n",
      "Epoch 474/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5882 - val_loss: 0.6489\n",
      "Epoch 475/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5735 - val_loss: 0.5973\n",
      "Epoch 476/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5793 - val_loss: 0.5682\n",
      "Epoch 477/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5713 - val_loss: 0.6075\n",
      "Epoch 478/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5863 - val_loss: 0.5818\n",
      "Epoch 479/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5824 - val_loss: 0.5614\n",
      "Epoch 480/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5699 - val_loss: 0.5841\n",
      "Epoch 481/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5890 - val_loss: 0.5830\n",
      "Epoch 482/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5962 - val_loss: 0.5794\n",
      "Epoch 483/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5846 - val_loss: 0.5797\n",
      "Epoch 484/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5885 - val_loss: 0.5821\n",
      "Epoch 485/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6023 - val_loss: 0.5991\n",
      "Epoch 486/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5976 - val_loss: 0.5953\n",
      "Epoch 487/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5819 - val_loss: 0.6595\n",
      "Epoch 488/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5901 - val_loss: 0.5818\n",
      "Epoch 489/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5872 - val_loss: 0.6034\n",
      "Epoch 490/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5793 - val_loss: 0.6269\n",
      "Epoch 491/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5913 - val_loss: 0.5685\n",
      "Epoch 492/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5794 - val_loss: 0.6175\n",
      "Epoch 493/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5841 - val_loss: 0.6088\n",
      "Epoch 494/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5835 - val_loss: 0.5685\n",
      "Epoch 495/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5729 - val_loss: 0.5569\n",
      "Epoch 496/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5697 - val_loss: 0.5906\n",
      "Epoch 497/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5831 - val_loss: 0.5855\n",
      "Epoch 498/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5721 - val_loss: 0.5674\n",
      "Epoch 499/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5977 - val_loss: 0.5693\n",
      "Epoch 500/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5775 - val_loss: 0.6429\n",
      "Epoch 501/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.5638\n",
      "Epoch 502/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5712 - val_loss: 0.5782\n",
      "Epoch 503/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5850 - val_loss: 0.5703\n",
      "Epoch 504/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.5730\n",
      "Epoch 505/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5742 - val_loss: 0.5875\n",
      "Epoch 506/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5740 - val_loss: 0.5535\n",
      "Epoch 507/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5937 - val_loss: 0.6070\n",
      "Epoch 508/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5721 - val_loss: 0.5881\n",
      "Epoch 509/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5589 - val_loss: 0.5745\n",
      "Epoch 510/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5691\n",
      "Epoch 511/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5676 - val_loss: 0.5707\n",
      "Epoch 512/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5717 - val_loss: 0.5881\n",
      "Epoch 513/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5658 - val_loss: 0.5661\n",
      "Epoch 514/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5781 - val_loss: 0.5912\n",
      "Epoch 515/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5787 - val_loss: 0.6152\n",
      "Epoch 516/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5647 - val_loss: 0.5748\n",
      "Epoch 517/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5642 - val_loss: 0.5758\n",
      "Epoch 518/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5680 - val_loss: 0.5827\n",
      "Epoch 519/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5909 - val_loss: 0.5725\n",
      "Epoch 520/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5791 - val_loss: 0.6184\n",
      "Epoch 521/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5744 - val_loss: 0.5626\n",
      "Epoch 522/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5836 - val_loss: 0.6608\n",
      "Epoch 523/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5930 - val_loss: 0.5733\n",
      "Epoch 524/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5702 - val_loss: 0.5598\n",
      "Epoch 525/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5834 - val_loss: 0.5934\n",
      "Epoch 526/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5764 - val_loss: 0.5696\n",
      "Epoch 527/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5842 - val_loss: 0.5696\n",
      "Epoch 528/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5651 - val_loss: 0.5664\n",
      "Epoch 529/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5769 - val_loss: 0.5822\n",
      "Epoch 530/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5916 - val_loss: 0.5629\n",
      "Epoch 531/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5817 - val_loss: 0.6851\n",
      "Epoch 532/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5667 - val_loss: 0.5879\n",
      "Epoch 533/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.5663\n",
      "Epoch 534/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5642 - val_loss: 0.5923\n",
      "Epoch 535/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5776 - val_loss: 0.5997\n",
      "Epoch 536/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5886 - val_loss: 0.6005\n",
      "Epoch 537/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5796 - val_loss: 0.5653\n",
      "Epoch 538/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5680 - val_loss: 0.5917\n",
      "Epoch 539/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5810 - val_loss: 0.5774\n",
      "Epoch 540/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5647 - val_loss: 0.5726\n",
      "Epoch 541/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5782 - val_loss: 0.6041\n",
      "Epoch 542/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5821 - val_loss: 0.5684\n",
      "Epoch 543/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5824 - val_loss: 0.5617\n",
      "Epoch 544/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5658 - val_loss: 0.5616\n",
      "Epoch 545/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5590 - val_loss: 0.5752\n",
      "Epoch 546/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5859 - val_loss: 0.5774\n",
      "Epoch 547/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5798 - val_loss: 0.5890\n",
      "Epoch 548/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5607 - val_loss: 0.5978\n",
      "Epoch 549/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5749 - val_loss: 0.5936\n",
      "Epoch 550/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5781 - val_loss: 0.5562\n",
      "Epoch 551/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5790 - val_loss: 0.5878\n",
      "Epoch 552/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5707 - val_loss: 0.5768\n",
      "Epoch 553/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5659 - val_loss: 0.5716\n",
      "Epoch 554/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5861 - val_loss: 0.5831\n",
      "Epoch 555/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5720 - val_loss: 0.5921\n",
      "Epoch 556/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.6082 - val_loss: 0.6011\n",
      "Epoch 557/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5834 - val_loss: 0.5747\n",
      "Epoch 558/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5863 - val_loss: 0.5832\n",
      "Epoch 559/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5711 - val_loss: 0.5867\n",
      "Epoch 560/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5595\n",
      "Epoch 561/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5733 - val_loss: 0.5892\n",
      "Epoch 562/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.5613\n",
      "Epoch 563/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5533 - val_loss: 0.5719\n",
      "Epoch 564/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5716 - val_loss: 0.6162\n",
      "Epoch 565/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5857 - val_loss: 0.5775\n",
      "Epoch 566/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5674 - val_loss: 0.5889\n",
      "Epoch 567/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5842 - val_loss: 0.5852\n",
      "Epoch 568/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5753 - val_loss: 0.5682\n",
      "Epoch 569/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5748 - val_loss: 0.5926\n",
      "Epoch 570/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.5586\n",
      "Epoch 571/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5739 - val_loss: 0.5655\n",
      "Epoch 572/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5666 - val_loss: 0.5745\n",
      "Epoch 573/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5632 - val_loss: 0.5948\n",
      "Epoch 574/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5726 - val_loss: 0.6014\n",
      "Epoch 575/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5677 - val_loss: 0.5587\n",
      "Epoch 576/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5613 - val_loss: 0.5700\n",
      "Epoch 577/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5838 - val_loss: 0.5801\n",
      "Epoch 578/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5723 - val_loss: 0.5765\n",
      "Epoch 579/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5717 - val_loss: 0.5918\n",
      "Epoch 580/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5766 - val_loss: 0.6181\n",
      "Epoch 581/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5535 - val_loss: 0.5631\n",
      "Epoch 582/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5740 - val_loss: 0.5671\n",
      "Epoch 583/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5539 - val_loss: 0.5710\n",
      "Epoch 584/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5896 - val_loss: 0.5948\n",
      "Epoch 585/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5700 - val_loss: 0.5637\n",
      "Epoch 586/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5676 - val_loss: 0.5698\n",
      "Epoch 587/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5828 - val_loss: 0.6011\n",
      "Epoch 588/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5620 - val_loss: 0.5617\n",
      "Epoch 589/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5647 - val_loss: 0.5902\n",
      "Epoch 590/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5664 - val_loss: 0.5676\n",
      "Epoch 591/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5781 - val_loss: 0.5847\n",
      "Epoch 592/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5780 - val_loss: 0.5925\n",
      "Epoch 593/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5747 - val_loss: 0.5487\n",
      "Epoch 594/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5616 - val_loss: 0.6184\n",
      "Epoch 595/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5617 - val_loss: 0.5703\n",
      "Epoch 596/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5680 - val_loss: 0.5799\n",
      "Epoch 597/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5800 - val_loss: 0.5662\n",
      "Epoch 598/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5739 - val_loss: 0.5610\n",
      "Epoch 599/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5645 - val_loss: 0.5608\n",
      "Epoch 600/600\n",
      "98/98 [==============================] - 0s 1ms/step - loss: 0.5502 - val_loss: 0.5860\n"
     ]
    }
   ],
   "source": [
    "#Fit model:\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_minitor = EarlyStopping(patience=200)\n",
    "\n",
    "#train model:   Test accuracy: 0.4959   epochs=300\n",
    "history = model.fit(x_train, y_train,\n",
    " epochs=600,\n",
    " batch_size=32,\n",
    " validation_split=0.2,\n",
    " callbacks=[early_stopping_minitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qInZXkyoYF2v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 580us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss of train and test set\n",
    "print(history.history.keys())\n",
    "\n",
    "#Loss in train and test:\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.02496195 7.        ]\n",
      " [5.92020416 5.        ]\n",
      " [5.00305939 5.        ]\n",
      " ...\n",
      " [5.00305939 5.        ]\n",
      " [5.88370323 6.        ]\n",
      " [5.00305939 4.        ]]\n"
     ]
    }
   ],
   "source": [
    "#y_pred = (y_pred > 0.5)\n",
    "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   4   4   0   0]\n",
      " [  0   0  31   5   0   0]\n",
      " [  0   0 215  82   0   0]\n",
      " [  0   0 125 289  10   0]\n",
      " [  0   0  13 140  22   0]\n",
      " [  0   0   7  31   2   0]]\n"
     ]
    }
   ],
   "source": [
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "print(cmatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.536734693877551"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.536734693877551\n"
     ]
    }
   ],
   "source": [
    "print('Test accuracy:', accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/wBa64zPEsVW1nNEJBUYF",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
