{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665327427202,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "8qtNdNTGPSxh"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665329164058,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "Z7p71Nq6PxEh"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"~/datacsv/HousingData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1665329166860,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "YNIOl21TP_rE",
    "outputId": "899b2c2a-7235-48a5-e2c1-a9a0d8e2047d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2253,
     "status": "ok",
     "timestamp": 1665329115505,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "iLB4dkFIWYJ3",
    "outputId": "c06626f8-7ac2-4d64-e977-04d4f6c7f5e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 14 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   CRIM     486 non-null    float64\n",
      " 1   ZN       486 non-null    float64\n",
      " 2   INDUS    486 non-null    float64\n",
      " 3   CHAS     486 non-null    float64\n",
      " 4   NOX      506 non-null    float64\n",
      " 5   RM       506 non-null    float64\n",
      " 6   AGE      486 non-null    float64\n",
      " 7   DIS      506 non-null    float64\n",
      " 8   RAD      506 non-null    int64  \n",
      " 9   TAX      506 non-null    int64  \n",
      " 10  PTRATIO  506 non-null    float64\n",
      " 11  B        506 non-null    float64\n",
      " 12  LSTAT    486 non-null    float64\n",
      " 13  MEDV     506 non-null    float64\n",
      "dtypes: float64(12), int64(2)\n",
      "memory usage: 55.5 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1665329938563,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "Pw242S_QWI1z",
    "outputId": "cc2b0149-6e28-4b95-ff3c-f767a7814d2a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRIM       20\n",
       "ZN         20\n",
       "INDUS      20\n",
       "CHAS       20\n",
       "NOX         0\n",
       "RM          0\n",
       "AGE        20\n",
       "DIS         0\n",
       "RAD         0\n",
       "TAX         0\n",
       "PTRATIO     0\n",
       "B           0\n",
       "LSTAT      20\n",
       "MEDV        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665330039050,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "2uniUlaQZnBJ"
   },
   "outputs": [],
   "source": [
    "data1=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 822,
     "status": "ok",
     "timestamp": 1665330052054,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "rqbEg87HQIf_"
   },
   "outputs": [],
   "source": [
    "x = data1.iloc[:,0:13].values\n",
    "y=data1.iloc[:,13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665330057103,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "FAFOgQSTQUhB",
    "outputId": "afb83821-572b-4e24-808b-35312ee92f37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "        4.9800e+00],\n",
       "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "        9.1400e+00],\n",
       "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "        4.0300e+00],\n",
       "       ...,\n",
       "       [4.5270e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        9.0800e+00],\n",
       "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "        5.6400e+00],\n",
       "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "        6.4800e+00]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1665330060482,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "RN7DLB4IQWDc",
    "outputId": "440eaabc-8c05-4db7-9e6a-c9d0b751d8a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 28.7, 27.1, 16.5, 15. , 18.9, 21.7, 20.4,\n",
       "       19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6, 15.2, 14.5, 15.6, 13.9,\n",
       "       16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2, 13.1, 13.5, 21. , 24.7,\n",
       "       30.8, 34.9, 26.6, 25.3, 21.2, 19.3, 20. , 14.4, 19.4, 19.7, 25. ,\n",
       "       18.9, 35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. ,\n",
       "       23.5, 19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 21.4, 20. , 20.8,\n",
       "       21.2, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 23.6, 28.7, 22.6,\n",
       "       22. , 25. , 20.6, 28.4, 21.4, 38.7, 43.8, 33.2, 27.5, 26.5, 18.6,\n",
       "       20.1, 19.5, 19.5, 20.4, 19.8, 19.4, 21.7, 22.8, 18.8, 18.7, 18.5,\n",
       "       19.2, 22. , 20.3, 20.5, 18.8, 21.4, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 15.6, 18.1, 17.4, 17.1, 17.8, 14. , 14.4, 13.4, 15.6, 11.8,\n",
       "       13.8, 15.4, 19.6, 19.4, 17. , 13.1, 24.3, 23.3, 27. , 50. , 50. ,\n",
       "       22.7, 25. , 50. , 23.8, 22.3, 17.4, 19.1, 23.1, 22.6, 29.4, 23.2,\n",
       "       29.9, 37.2, 39.8, 36.2, 37.9, 26.4, 29.6, 32. , 29.8, 34.9, 37. ,\n",
       "       29.1, 50. , 30.3, 34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 24.4,\n",
       "       20. , 19.3, 22.4, 28.1, 23.7, 23.3, 28.7, 21.5, 26.7, 21.7, 27.5,\n",
       "       30.1, 44.8, 50. , 31.6, 24.3, 31.7, 41.7, 29. , 24. , 31.5, 23.3,\n",
       "       22.2, 23.7, 17.6, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6, 42.8,\n",
       "       20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 31. , 36.5, 22.8, 50. ,\n",
       "       43.5, 20.7, 21.1, 24.4, 35.2, 32.4, 32. , 33.2, 29.1, 35.1, 45.4,\n",
       "       46. , 50. , 32.2, 22. , 23.2, 24.8, 28.5, 37.3, 23.9, 28.6, 27.1,\n",
       "       22.5, 29. , 24.8, 36.1, 33.4, 28.2, 22.8, 20.3, 16.1, 22.1, 19.4,\n",
       "       21.6, 23.8, 16.2, 19.8, 23.1, 21. , 23.8, 23.1, 20.4, 18.5, 25. ,\n",
       "       24.6, 23. , 22.2, 19.3, 22.6, 17.1, 22.2, 20.7, 21.1, 19.5, 18.5,\n",
       "       20.6, 19. , 18.7, 32.7, 16.5, 23.9, 17.5, 17.2, 23.1, 24.5, 24.1,\n",
       "       18.6, 30.1, 18.2, 17.8, 21.7, 22.7, 25. , 19.9, 20.8, 16.8, 21.9,\n",
       "       27.5, 21.9, 50. , 50. , 50. , 13.8, 13.8, 13.3, 13.1, 10.2, 10.4,\n",
       "       10.9, 11.3,  8.8,  7.2, 10.5,  7.4, 11.5, 15.1, 23.2,  9.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6, 12.1,  8.3,  8.5,  5. , 17.2, 15. ,\n",
       "       17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,  8.8,  8.4, 16.7, 14.2,\n",
       "       20.8, 11.7,  8.3, 11. , 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,\n",
       "        8.4, 12.8, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 16.1, 14.9,\n",
       "       14.1, 12.7, 13.5, 20. , 17.7, 19.5, 20.2, 21.4, 19.1, 19.1, 20.1,\n",
       "       19.9, 19.6, 23.2, 13.8, 13.3, 16.7, 12. , 14.6, 23. , 23.7, 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 20.6, 23.9, 22. ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UEENwze_UTyC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665330065074,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "TVNxfzm5QW8f"
   },
   "outputs": [],
   "source": [
    "# splitting the training & test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1665330068344,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "r0LO-ofKUhSB"
   },
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mc=MinMaxScaler()\n",
    "x_train1 = mc.fit_transform( x_train)\n",
    "X_test1 = mc.fit_transform( x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1665329231326,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "qCrZ1bbYRHjL"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1665330071253,
     "user": {
      "displayName": "shaik azar",
      "userId": "05209245971384166097"
     },
     "user_tz": -330
    },
    "id": "YzDCMeK3Rt6G"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 104)               1456      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 104)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 52)                5460      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 52)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 26)                1378      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 26)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,321\n",
      "Trainable params: 8,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model=Sequential()\n",
    "\n",
    "# Build input layer & Hidden layer\n",
    "model.add(Dense(units=104, activation='relu', input_dim=13))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "# Building second layer\n",
    "model.add(Dense(units=52,activation ='relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "# Building third layer\n",
    "model.add(Dense(units=26,activation ='relu'))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "#Adding outer layer\n",
    "model.add(Dense(units = 1, activation='linear'))\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='mae')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 39.6231 - val_loss: 22.8881\n",
      "Epoch 2/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 20.7498 - val_loss: 14.3994\n",
      "Epoch 3/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 15.4612 - val_loss: 11.0071\n",
      "Epoch 4/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11.5168 - val_loss: 6.4027\n",
      "Epoch 5/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.9489 - val_loss: 9.4750\n",
      "Epoch 6/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.4334 - val_loss: 6.9053\n",
      "Epoch 7/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.0070 - val_loss: 8.3585\n",
      "Epoch 8/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 9.0540 - val_loss: 7.3014\n",
      "Epoch 9/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.6411 - val_loss: 5.8014\n",
      "Epoch 10/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.7550 - val_loss: 6.3032\n",
      "Epoch 11/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 8.0032 - val_loss: 5.9066\n",
      "Epoch 12/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.2770 - val_loss: 5.9876\n",
      "Epoch 13/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 8.0832 - val_loss: 5.8973\n",
      "Epoch 14/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.6072 - val_loss: 5.9176\n",
      "Epoch 15/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.7819 - val_loss: 5.4333\n",
      "Epoch 16/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 7.5099 - val_loss: 6.8485\n",
      "Epoch 17/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.3476 - val_loss: 5.9002\n",
      "Epoch 18/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.3544 - val_loss: 6.3443\n",
      "Epoch 19/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.3492 - val_loss: 5.6434\n",
      "Epoch 20/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.7294 - val_loss: 5.0309\n",
      "Epoch 21/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.1224 - val_loss: 6.7784\n",
      "Epoch 22/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.7369 - val_loss: 5.4678\n",
      "Epoch 23/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.4928 - val_loss: 5.2413\n",
      "Epoch 24/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.3116 - val_loss: 6.7131\n",
      "Epoch 25/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.9719 - val_loss: 4.9930\n",
      "Epoch 26/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 7.2712 - val_loss: 5.2295\n",
      "Epoch 27/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.6819 - val_loss: 5.7689\n",
      "Epoch 28/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.6407 - val_loss: 4.9745\n",
      "Epoch 29/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.9745 - val_loss: 5.4977\n",
      "Epoch 30/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.4165 - val_loss: 5.6691\n",
      "Epoch 31/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.6779 - val_loss: 5.3783\n",
      "Epoch 32/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2434 - val_loss: 5.3180\n",
      "Epoch 33/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 7.1930 - val_loss: 4.8878\n",
      "Epoch 34/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2161 - val_loss: 5.2708\n",
      "Epoch 35/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.5007 - val_loss: 4.7722\n",
      "Epoch 36/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2992 - val_loss: 5.5815\n",
      "Epoch 37/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2737 - val_loss: 5.2832\n",
      "Epoch 38/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.6632 - val_loss: 4.8677\n",
      "Epoch 39/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2814 - val_loss: 5.4483\n",
      "Epoch 40/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.3452 - val_loss: 4.8233\n",
      "Epoch 41/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.9610 - val_loss: 5.1341\n",
      "Epoch 42/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.3818 - val_loss: 4.9673\n",
      "Epoch 43/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4212 - val_loss: 5.2078\n",
      "Epoch 44/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.1246 - val_loss: 5.1300\n",
      "Epoch 45/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.7312 - val_loss: 5.3992\n",
      "Epoch 46/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.9543 - val_loss: 4.7121\n",
      "Epoch 47/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.3861 - val_loss: 4.8498\n",
      "Epoch 48/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2048 - val_loss: 5.3911\n",
      "Epoch 49/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.7013 - val_loss: 4.8991\n",
      "Epoch 50/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.5478 - val_loss: 5.0938\n",
      "Epoch 51/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.3059 - val_loss: 4.7324\n",
      "Epoch 52/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.3144 - val_loss: 4.6909\n",
      "Epoch 53/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.7434 - val_loss: 4.8205\n",
      "Epoch 54/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.3608 - val_loss: 4.7849\n",
      "Epoch 55/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.9978 - val_loss: 4.6756\n",
      "Epoch 56/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.0071 - val_loss: 4.9282\n",
      "Epoch 57/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.9840 - val_loss: 4.9498\n",
      "Epoch 58/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.3074 - val_loss: 5.1336\n",
      "Epoch 59/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.2073 - val_loss: 5.2650\n",
      "Epoch 60/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.7412 - val_loss: 4.5762\n",
      "Epoch 61/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.7005 - val_loss: 4.5275\n",
      "Epoch 62/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5893 - val_loss: 4.7957\n",
      "Epoch 63/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.8112 - val_loss: 4.6730\n",
      "Epoch 64/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.8113 - val_loss: 5.4566\n",
      "Epoch 65/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.9525 - val_loss: 4.8053\n",
      "Epoch 66/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 6.1129 - val_loss: 5.0385\n",
      "Epoch 67/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5806 - val_loss: 4.8167\n",
      "Epoch 68/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.6505 - val_loss: 4.9229\n",
      "Epoch 69/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2864 - val_loss: 5.7173\n",
      "Epoch 70/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5620 - val_loss: 4.5195\n",
      "Epoch 71/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5584 - val_loss: 5.5650\n",
      "Epoch 72/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.2290 - val_loss: 4.3845\n",
      "Epoch 73/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3446 - val_loss: 5.0451\n",
      "Epoch 74/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5971 - val_loss: 4.6371\n",
      "Epoch 75/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5126 - val_loss: 4.8933\n",
      "Epoch 76/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5016 - val_loss: 4.5833\n",
      "Epoch 77/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.8211 - val_loss: 4.3914\n",
      "Epoch 78/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3922 - val_loss: 4.5375\n",
      "Epoch 79/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.7479 - val_loss: 4.5641\n",
      "Epoch 80/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.7789 - val_loss: 4.4277\n",
      "Epoch 81/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 6.0313 - val_loss: 4.3426\n",
      "Epoch 82/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.8666 - val_loss: 4.6134\n",
      "Epoch 83/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4638 - val_loss: 4.4674\n",
      "Epoch 84/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5797 - val_loss: 4.8052\n",
      "Epoch 85/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.4377 - val_loss: 4.3726\n",
      "Epoch 86/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.6874 - val_loss: 4.7648\n",
      "Epoch 87/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.6153 - val_loss: 4.2172\n",
      "Epoch 88/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5596 - val_loss: 5.1735\n",
      "Epoch 89/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2680 - val_loss: 4.5159\n",
      "Epoch 90/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.7600 - val_loss: 4.1812\n",
      "Epoch 91/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2850 - val_loss: 5.1052\n",
      "Epoch 92/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1394 - val_loss: 4.2965\n",
      "Epoch 93/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.2360 - val_loss: 4.3117\n",
      "Epoch 94/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5278 - val_loss: 4.5820\n",
      "Epoch 95/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.8129 - val_loss: 4.8495\n",
      "Epoch 96/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4852 - val_loss: 4.8796\n",
      "Epoch 97/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2454 - val_loss: 4.2177\n",
      "Epoch 98/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.6923 - val_loss: 4.3422\n",
      "Epoch 99/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5157 - val_loss: 4.3223\n",
      "Epoch 100/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.5459 - val_loss: 4.2735\n",
      "Epoch 101/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.4687 - val_loss: 4.1802\n",
      "Epoch 102/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2203 - val_loss: 4.2772\n",
      "Epoch 103/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3544 - val_loss: 4.2675\n",
      "Epoch 104/200\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 5.2822 - val_loss: 4.2513\n",
      "Epoch 105/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2550 - val_loss: 4.2423\n",
      "Epoch 106/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0560 - val_loss: 4.2871\n",
      "Epoch 107/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.3494 - val_loss: 4.7592\n",
      "Epoch 108/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3848 - val_loss: 4.0526\n",
      "Epoch 109/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.9378 - val_loss: 4.2889\n",
      "Epoch 110/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8974 - val_loss: 4.2402\n",
      "Epoch 111/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7985 - val_loss: 4.1446\n",
      "Epoch 112/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.1691 - val_loss: 4.8047\n",
      "Epoch 113/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.9630 - val_loss: 4.0835\n",
      "Epoch 114/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.0975 - val_loss: 4.4453\n",
      "Epoch 115/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.3923 - val_loss: 4.0571\n",
      "Epoch 116/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.3059 - val_loss: 5.0412\n",
      "Epoch 117/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0375 - val_loss: 4.2962\n",
      "Epoch 118/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.8972 - val_loss: 4.3608\n",
      "Epoch 119/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.8435 - val_loss: 4.2880\n",
      "Epoch 120/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0874 - val_loss: 4.4977\n",
      "Epoch 121/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1861 - val_loss: 4.4117\n",
      "Epoch 122/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1228 - val_loss: 5.2962\n",
      "Epoch 123/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.2170 - val_loss: 4.0964\n",
      "Epoch 124/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1490 - val_loss: 5.0596\n",
      "Epoch 125/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8733 - val_loss: 3.9482\n",
      "Epoch 126/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1565 - val_loss: 4.5712\n",
      "Epoch 127/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0328 - val_loss: 4.2481\n",
      "Epoch 128/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.1317 - val_loss: 4.8559\n",
      "Epoch 129/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9683 - val_loss: 4.1274\n",
      "Epoch 130/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.0930 - val_loss: 4.3740\n",
      "Epoch 131/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.0216 - val_loss: 4.4027\n",
      "Epoch 132/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8159 - val_loss: 4.7686\n",
      "Epoch 133/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9996 - val_loss: 4.4575\n",
      "Epoch 134/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7200 - val_loss: 4.3345\n",
      "Epoch 135/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6147 - val_loss: 3.9474\n",
      "Epoch 136/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 5.1408 - val_loss: 4.6839\n",
      "Epoch 137/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 5.3556 - val_loss: 4.0339\n",
      "Epoch 138/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9670 - val_loss: 4.4959\n",
      "Epoch 139/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.5619 - val_loss: 3.8277\n",
      "Epoch 140/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8379 - val_loss: 4.6844\n",
      "Epoch 141/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.8294 - val_loss: 3.9191\n",
      "Epoch 142/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.7238 - val_loss: 4.1352\n",
      "Epoch 143/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7170 - val_loss: 4.8610\n",
      "Epoch 144/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7871 - val_loss: 3.7951\n",
      "Epoch 145/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.8947 - val_loss: 4.5285\n",
      "Epoch 146/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7887 - val_loss: 3.7757\n",
      "Epoch 147/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7874 - val_loss: 4.7432\n",
      "Epoch 148/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3701 - val_loss: 4.3169\n",
      "Epoch 149/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7114 - val_loss: 3.9696\n",
      "Epoch 150/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6530 - val_loss: 4.0019\n",
      "Epoch 151/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9497 - val_loss: 3.9418\n",
      "Epoch 152/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6696 - val_loss: 4.9163\n",
      "Epoch 153/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3988 - val_loss: 3.7885\n",
      "Epoch 154/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6847 - val_loss: 5.2070\n",
      "Epoch 155/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.7513 - val_loss: 3.7493\n",
      "Epoch 156/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7162 - val_loss: 5.3369\n",
      "Epoch 157/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5727 - val_loss: 4.0162\n",
      "Epoch 158/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9044 - val_loss: 5.3482\n",
      "Epoch 159/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.9140 - val_loss: 4.0736\n",
      "Epoch 160/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4726 - val_loss: 4.6657\n",
      "Epoch 161/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5993 - val_loss: 4.1914\n",
      "Epoch 162/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.5535 - val_loss: 4.3218\n",
      "Epoch 163/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4996 - val_loss: 4.1433\n",
      "Epoch 164/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.1487 - val_loss: 4.8869\n",
      "Epoch 165/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4756 - val_loss: 3.9608\n",
      "Epoch 166/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6336 - val_loss: 4.6093\n",
      "Epoch 167/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4289 - val_loss: 3.7245\n",
      "Epoch 168/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7300 - val_loss: 5.0684\n",
      "Epoch 169/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6385 - val_loss: 4.0349\n",
      "Epoch 170/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4871 - val_loss: 4.0089\n",
      "Epoch 171/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4177 - val_loss: 5.0195\n",
      "Epoch 172/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.6766 - val_loss: 3.8173\n",
      "Epoch 173/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7410 - val_loss: 6.2890\n",
      "Epoch 174/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.7884 - val_loss: 3.9253\n",
      "Epoch 175/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3216 - val_loss: 4.2854\n",
      "Epoch 176/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3284 - val_loss: 3.7648\n",
      "Epoch 177/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6827 - val_loss: 4.3563\n",
      "Epoch 178/200\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4.4436 - val_loss: 3.7824\n",
      "Epoch 179/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6062 - val_loss: 3.9593\n",
      "Epoch 180/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 3.9511 - val_loss: 3.9641\n",
      "Epoch 181/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2113 - val_loss: 4.2128\n",
      "Epoch 182/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3407 - val_loss: 3.7724\n",
      "Epoch 183/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4684 - val_loss: 3.7574\n",
      "Epoch 184/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6059 - val_loss: 5.2423\n",
      "Epoch 185/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.6012 - val_loss: 3.6761\n",
      "Epoch 186/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4943 - val_loss: 4.8222\n",
      "Epoch 187/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1293 - val_loss: 3.7433\n",
      "Epoch 188/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3565 - val_loss: 4.3535\n",
      "Epoch 189/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2352 - val_loss: 3.8774\n",
      "Epoch 190/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1699 - val_loss: 3.9482\n",
      "Epoch 191/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1998 - val_loss: 4.8835\n",
      "Epoch 192/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1826 - val_loss: 4.0434\n",
      "Epoch 193/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1812 - val_loss: 3.8827\n",
      "Epoch 194/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4203 - val_loss: 4.9812\n",
      "Epoch 195/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.1441 - val_loss: 3.7314\n",
      "Epoch 196/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3151 - val_loss: 4.5404\n",
      "Epoch 197/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3752 - val_loss: 4.1507\n",
      "Epoch 198/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.2671 - val_loss: 3.6931\n",
      "Epoch 199/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.4497 - val_loss: 5.1871\n",
      "Epoch 200/200\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 4.3451 - val_loss: 3.6956\n"
     ]
    }
   ],
   "source": [
    "#Fit model:\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stopping_minitor = EarlyStopping(patience=200)\n",
    "\n",
    "#train model:\n",
    "history = model.fit(x_train, y_train,\n",
    " epochs=200,\n",
    " batch_size=32,\n",
    " validation_split=0.2,\n",
    " callbacks=[early_stopping_minitor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "qInZXkyoYF2v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'val_loss'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss of train and test set\n",
    "print(history.history.keys())\n",
    "\n",
    "#Loss in train and test:\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test data\n",
      "10/10 [==============================] - 0s 651us/step - loss: 3.3735\n",
      "mae:  3.3734731674194336\n"
     ]
    }
   ],
   "source": [
    "#evaluate the result\n",
    "print('Evaluation on test data')\n",
    "results = model.evaluate(x_train, y_train)\n",
    "print('mae: ', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    506.000000\n",
       "mean      22.532806\n",
       "std        9.197104\n",
       "min        5.000000\n",
       "25%       17.025000\n",
       "50%       21.200000\n",
       "75%       25.000000\n",
       "max       50.000000\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.MEDV.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14957833999112294"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mae/mean ratio : 14%\n",
    "\n",
    "3.37/22.53"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN/wBa64zPEsVW1nNEJBUYF",
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
